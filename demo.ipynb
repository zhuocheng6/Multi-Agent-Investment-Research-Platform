{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d0b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPROVED AGENT RESULT PARSING\n",
    "# Instead of text parsing, use structured JSON responses\n",
    "\n",
    "class StructuredAgentResponse:\n",
    "    \"\"\"Force agents to return structured data\"\"\"\n",
    "    \n",
    "    AGENT_RESPONSE_SCHEMA = \"\"\"\n",
    "    You must return your analysis in the following JSON format:\n",
    "    {\n",
    "        \"recommendation\": \"BUY|HOLD|SELL\",\n",
    "        \"confidence_score\": 0.0-1.0,\n",
    "        \"price_target\": float,\n",
    "        \"stop_loss\": float,\n",
    "        \"key_metrics\": {\n",
    "            \"metric_name\": value\n",
    "        },\n",
    "        \"risks\": [\"risk1\", \"risk2\"],\n",
    "        \"opportunities\": [\"opp1\", \"opp2\"],\n",
    "        \"reasoning\": \"detailed explanation\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def parse_agent_response(response_text: str) -> dict:\n",
    "        \"\"\"Extract JSON from agent response\"\"\"\n",
    "        import re\n",
    "        import json\n",
    "        \n",
    "        # Find JSON block in response\n",
    "        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            try:\n",
    "                return json.loads(json_match.group())\n",
    "            except json.JSONDecodeError:\n",
    "                pass\n",
    "        \n",
    "        # Fallback to text parsing if JSON fails\n",
    "        return StructuredAgentResponse._fallback_parse(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b04ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. AGENT MEMORY & LEARNING SYSTEM\n",
    "class AgentMemorySystem:\n",
    "    \"\"\"Enable agents to learn from past analyses\"\"\"\n",
    "    \n",
    "    def __init__(self, db_path: str = \"agent_memory.db\"):\n",
    "        import sqlite3\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self._initialize_db()\n",
    "    \n",
    "    def _initialize_db(self):\n",
    "        \"\"\"Create tables for storing agent knowledge\"\"\"\n",
    "        self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS analysis_history (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                ticker TEXT,\n",
    "                agent_name TEXT,\n",
    "                recommendation TEXT,\n",
    "                confidence REAL,\n",
    "                price_at_recommendation REAL,\n",
    "                timestamp DATETIME,\n",
    "                outcome_30d REAL,\n",
    "                outcome_90d REAL\n",
    "            )\n",
    "        \"\"\")\n",
    "        \n",
    "        self.conn.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS agent_patterns (\n",
    "                agent_name TEXT,\n",
    "                pattern_type TEXT,\n",
    "                pattern_data JSON,\n",
    "                success_rate REAL,\n",
    "                sample_count INTEGER\n",
    "            )\n",
    "        \"\"\")\n",
    "    \n",
    "    def store_analysis(self, agent_name: str, ticker: str, result: dict):\n",
    "        \"\"\"Store analysis for future learning\"\"\"\n",
    "        self.conn.execute(\"\"\"\n",
    "            INSERT INTO analysis_history \n",
    "            (ticker, agent_name, recommendation, confidence, price_at_recommendation, timestamp)\n",
    "            VALUES (?, ?, ?, ?, ?, datetime('now'))\n",
    "        \"\"\", (ticker, agent_name, result['recommendation'], \n",
    "              result['confidence'], result['current_price']))\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def get_agent_performance(self, agent_name: str) -> dict:\n",
    "        \"\"\"Retrieve historical performance metrics\"\"\"\n",
    "        cursor = self.conn.execute(\"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as total,\n",
    "                AVG(CASE WHEN outcome_30d > 0 THEN 1 ELSE 0 END) as success_rate_30d,\n",
    "                AVG(confidence) as avg_confidence,\n",
    "                AVG(ABS(confidence - ABS(outcome_30d/price_at_recommendation))) as calibration_error\n",
    "            FROM analysis_history\n",
    "            WHERE agent_name = ? AND outcome_30d IS NOT NULL\n",
    "        \"\"\", (agent_name,))\n",
    "        \n",
    "        return dict(cursor.fetchone())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11670354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. REAL-TIME DATA STREAMING\n",
    "class RealTimeDataManager:\n",
    "    \"\"\"Manage real-time data feeds for agents\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.websocket_connections = {}\n",
    "        self.data_buffers = {}\n",
    "    \n",
    "    async def connect_market_data(self, ticker: str):\n",
    "        \"\"\"Establish WebSocket connection for real-time data\"\"\"\n",
    "        # In production, connect to actual market data providers\n",
    "        # For demo, simulate with periodic updates\n",
    "        import asyncio\n",
    "        import random\n",
    "        \n",
    "        async def simulate_price_stream():\n",
    "            base_price = 100\n",
    "            while True:\n",
    "                yield {\n",
    "                    'ticker': ticker,\n",
    "                    'price': base_price * (1 + random.uniform(-0.02, 0.02)),\n",
    "                    'volume': random.randint(1000000, 5000000),\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                }\n",
    "                await asyncio.sleep(1)\n",
    "        \n",
    "        self.data_buffers[ticker] = simulate_price_stream()\n",
    "    \n",
    "    async def get_latest_data(self, ticker: str, window_seconds: int = 60):\n",
    "        \"\"\"Get recent data window for analysis\"\"\"\n",
    "        if ticker not in self.data_buffers:\n",
    "            await self.connect_market_data(ticker)\n",
    "        \n",
    "        data_points = []\n",
    "        async for data in self.data_buffers[ticker]:\n",
    "            data_points.append(data)\n",
    "            if len(data_points) >= window_seconds:\n",
    "                break\n",
    "        \n",
    "        return data_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4baa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.13/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.13/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2887d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. BACKTESTING & VALIDATION SYSTEM\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "class BacktestingEngine:\n",
    "    \"\"\"Validate agent recommendations with historical data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.historical_data = {}\n",
    "    \n",
    "    async def backtest_strategy(self, ticker: str, strategy: dict, \n",
    "                                start_date: str, end_date: str) -> dict:\n",
    "        \"\"\"Backtest investment strategy\"\"\"\n",
    "        import yfinance as yf\n",
    "        import pandas as pd\n",
    "        \n",
    "        # Get historical data\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist = stock.history(start=start_date, end=end_date)\n",
    "        \n",
    "        # Simulate trades based on strategy\n",
    "        positions = []\n",
    "        cash = 100000  # Starting capital\n",
    "        shares = 0\n",
    "        \n",
    "        for date, row in hist.iterrows():\n",
    "            # Simplified backtesting logic\n",
    "            signal = self._generate_signal(row, strategy)\n",
    "            \n",
    "            if signal == 'BUY' and cash > row['Close']:\n",
    "                shares_to_buy = int(cash * 0.95 / row['Close'])  # Use 95% of cash\n",
    "                if shares_to_buy > 0:\n",
    "                    positions.append({\n",
    "                        'date': date,\n",
    "                        'action': 'BUY',\n",
    "                        'price': row['Close'],\n",
    "                        'shares': shares_to_buy\n",
    "                    })\n",
    "                    cash -= shares_to_buy * row['Close']\n",
    "                    shares += shares_to_buy\n",
    "            \n",
    "            elif signal == 'SELL' and shares > 0:\n",
    "                positions.append({\n",
    "                    'date': date,\n",
    "                    'action': 'SELL',\n",
    "                    'price': row['Close'],\n",
    "                    'shares': shares\n",
    "                })\n",
    "                cash += shares * row['Close']\n",
    "                shares = 0\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        final_value = cash + shares * hist['Close'].iloc[-1]\n",
    "        total_return = (final_value - 100000) / 100000\n",
    "        \n",
    "        # Calculate Sharpe ratio\n",
    "        if positions:\n",
    "            returns = pd.Series([p['price'] for p in positions if p['action'] == 'SELL']).pct_change()\n",
    "            sharpe = returns.mean() / returns.std() * (252 ** 0.5) if len(returns) > 1 else 0\n",
    "        else:\n",
    "            sharpe = 0\n",
    "        \n",
    "        return {\n",
    "            'total_return': total_return,\n",
    "            'final_value': final_value,\n",
    "            'num_trades': len(positions),\n",
    "            'sharpe_ratio': sharpe,\n",
    "            'positions': positions\n",
    "        }\n",
    "    \n",
    "    def _generate_signal(self, row: pd.Series, strategy: dict) -> str:\n",
    "        \"\"\"Generate trading signal based on strategy\"\"\"\n",
    "        # Simplified signal generation\n",
    "        if row['Close'] > row['Open'] * 1.02:  # 2% gain\n",
    "            return 'SELL'\n",
    "        elif row['Close'] < row['Open'] * 0.98:  # 2% loss\n",
    "            return 'BUY'\n",
    "        return 'HOLD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45a2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. EXPLAINABLE AI LAYER\n",
    "class ExplainabilityEngine:\n",
    "    \"\"\"Make agent decisions transparent and explainable\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.explanation_templates = {\n",
    "            'fundamental': \"Based on P/E ratio of {pe:.1f} (vs industry avg {ind_pe:.1f}), \"\n",
    "                          \"profit margin of {margin:.1%}, and debt/equity of {de:.2f}\",\n",
    "            'technical': \"Price is {price_vs_ma:.1%} above 50-day MA, RSI at {rsi:.1f}, \"\n",
    "                        \"MACD shows {macd_signal} signal\",\n",
    "            'sentiment': \"News sentiment score: {sentiment:.2f}, {num_articles} articles analyzed, \"\n",
    "                        \"dominant theme: {theme}\"\n",
    "        }\n",
    "    \n",
    "    def generate_explanation(self, agent_name: str, metrics: dict) -> str:\n",
    "        \"\"\"Generate human-readable explanation for agent decision\"\"\"\n",
    "        template = self.explanation_templates.get(agent_name, \"\")\n",
    "        try:\n",
    "            return template.format(**metrics)\n",
    "        except KeyError:\n",
    "            return f\"Agent {agent_name} recommendation based on proprietary analysis\"\n",
    "    \n",
    "    def create_decision_tree(self, results: dict) -> dict:\n",
    "        \"\"\"Create decision tree showing how final recommendation was reached\"\"\"\n",
    "        tree = {\n",
    "            'root': 'Final Recommendation',\n",
    "            'branches': []\n",
    "        }\n",
    "        \n",
    "        for agent_name, result in results.items():\n",
    "            branch = {\n",
    "                'agent': agent_name,\n",
    "                'recommendation': result.get('recommendation'),\n",
    "                'confidence': result.get('confidence_score'),\n",
    "                'key_factors': result.get('key_metrics', {}),\n",
    "                'weight': result.get('weight', 0.25)\n",
    "            }\n",
    "            tree['branches'].append(branch)\n",
    "        \n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d78f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. RISK MANAGEMENT FRAMEWORK\n",
    "class RiskManagementSystem:\n",
    "    \"\"\"Advanced risk management and position sizing\"\"\"\n",
    "    \n",
    "    def __init__(self, risk_tolerance: str = 'moderate'):\n",
    "        self.risk_profiles = {\n",
    "            'conservative': {'max_position': 0.05, 'stop_loss': 0.05, 'var_limit': 0.02},\n",
    "            'moderate': {'max_position': 0.10, 'stop_loss': 0.08, 'var_limit': 0.05},\n",
    "            'aggressive': {'max_position': 0.20, 'stop_loss': 0.15, 'var_limit': 0.10}\n",
    "        }\n",
    "        self.profile = self.risk_profiles[risk_tolerance]\n",
    "    \n",
    "    def calculate_position_size(self, portfolio_value: float, ticker_analysis: dict) -> dict:\n",
    "        \"\"\"Calculate optimal position size based on Kelly Criterion and risk limits\"\"\"\n",
    "        confidence = ticker_analysis.get('confidence_score', 0.5)\n",
    "        expected_return = ticker_analysis.get('expected_return', 0.1)\n",
    "        volatility = ticker_analysis.get('volatility', 0.2)\n",
    "        \n",
    "        # Kelly Criterion\n",
    "        kelly_fraction = (confidence * expected_return) / (volatility ** 2)\n",
    "        kelly_fraction = max(0, min(kelly_fraction, 1))  # Bound between 0 and 1\n",
    "        \n",
    "        # Apply risk limits\n",
    "        max_position = self.profile['max_position']\n",
    "        recommended_position = min(kelly_fraction * 0.25, max_position)  # Use 25% of Kelly\n",
    "        \n",
    "        position_value = portfolio_value * recommended_position\n",
    "        \n",
    "        return {\n",
    "            'position_size_pct': recommended_position,\n",
    "            'position_value': position_value,\n",
    "            'stop_loss_pct': self.profile['stop_loss'],\n",
    "            'risk_amount': position_value * self.profile['stop_loss'],\n",
    "            'kelly_fraction': kelly_fraction\n",
    "        }\n",
    "    \n",
    "    def calculate_portfolio_var(self, positions: list, confidence_level: float = 0.95) -> float:\n",
    "        \"\"\"Calculate Value at Risk for portfolio\"\"\"\n",
    "        import numpy as np\n",
    "        from scipy import stats\n",
    "        \n",
    "        # Simplified VaR calculation\n",
    "        returns = [p.get('expected_return', 0) for p in positions]\n",
    "        volatilities = [p.get('volatility', 0.2) for p in positions]\n",
    "        weights = [p.get('weight', 0) for p in positions]\n",
    "        \n",
    "        # Portfolio metrics\n",
    "        portfolio_return = np.dot(weights, returns)\n",
    "        portfolio_vol = np.sqrt(np.dot(weights, np.square(volatilities)))\n",
    "        \n",
    "        # VaR calculation\n",
    "        z_score = stats.norm.ppf(1 - confidence_level)\n",
    "        var = portfolio_return + z_score * portfolio_vol\n",
    "        \n",
    "        return abs(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72ccd836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. INTEGRATION WITH EXTERNAL SYSTEMS\n",
    "class ExternalIntegrations:\n",
    "    \"\"\"Connect with trading platforms and data providers\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.supported_brokers = ['alpaca', 'interactive_brokers', 'td_ameritrade']\n",
    "        self.data_providers = ['polygon', 'alpha_vantage', 'quandl']\n",
    "    \n",
    "    async def execute_trade(self, broker: str, order: dict) -> dict:\n",
    "        \"\"\"Execute trade through broker API\"\"\"\n",
    "        if broker not in self.supported_brokers:\n",
    "            raise ValueError(f\"Unsupported broker: {broker}\")\n",
    "        \n",
    "        # In production, implement actual broker APIs\n",
    "        # For demo, simulate trade execution\n",
    "        import random\n",
    "        \n",
    "        execution_price = order['limit_price'] * (1 + random.uniform(-0.001, 0.001))\n",
    "        \n",
    "        return {\n",
    "            'order_id': f\"ORD-{random.randint(100000, 999999)}\",\n",
    "            'status': 'filled',\n",
    "            'filled_price': execution_price,\n",
    "            'filled_quantity': order['quantity'],\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    async def get_alternative_data(self, ticker: str, data_type: str) -> dict:\n",
    "        \"\"\"Fetch alternative data (satellite, web scraping, etc.)\"\"\"\n",
    "        alternative_data_sources = {\n",
    "            'social_sentiment': self._get_social_sentiment,\n",
    "            'satellite_data': self._get_satellite_data,\n",
    "            'web_traffic': self._get_web_traffic,\n",
    "            'job_postings': self._get_job_postings\n",
    "        }\n",
    "        \n",
    "        if data_type in alternative_data_sources:\n",
    "            return await alternative_data_sources[data_type](ticker)\n",
    "        \n",
    "        return {'error': f'Unknown data type: {data_type}'}\n",
    "    \n",
    "    async def _get_social_sentiment(self, ticker: str) -> dict:\n",
    "        \"\"\"Simulate social media sentiment data\"\"\"\n",
    "        import random\n",
    "        return {\n",
    "            'ticker': ticker,\n",
    "            'reddit_mentions': random.randint(10, 1000),\n",
    "            'twitter_sentiment': random.uniform(-1, 1),\n",
    "            'stocktwits_bullish_pct': random.uniform(0.3, 0.7)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f4121d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c9c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your API keys here\n",
    "os.environ['GOOGLE_API_KEY'] = 'your-gemini-api-key-here'  # REQUIRED\n",
    "os.environ['SEC_API_KEY'] = 'your-sec-api-key-here'        # Optional but recommended\n",
    "os.environ['NEWS_API_KEY'] = 'your-news-api-key-here'      # Optional but recommended\n",
    "\n",
    "# Disable Vertex AI (use Google AI Studio instead)\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n",
    "\n",
    "# Verify keys are set\n",
    "print(\"✅ Google API Key:\", \"Set\" if os.environ.get('GOOGLE_API_KEY') else \"❌ Missing\")\n",
    "print(\"✅ SEC API Key:\", \"Set\" if os.environ.get('SEC_API_KEY') else \"⚠️ Missing (some features disabled)\")\n",
    "print(\"✅ News API Key:\", \"Set\" if os.environ.get('NEWS_API_KEY') else \"⚠️ Missing (some features disabled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c30534e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
